{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables and setting up a session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "\n",
    "f = x*x*y + y + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#Setting up a session\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()    #always be closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#Using tf.global_variables_initializer() to initialize all variables together\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)    #or init.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With InteractiveSession()\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()    #or sess.run(init)\n",
    "result = f.eval()\n",
    "#print(result)\n",
    "\n",
    "#you have to close the session if you use InteractiveSession()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Any node you create is automatically added to the default graph\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "print(x2.graph is graph)    #it is a graph\n",
    "print(x2.graph is tf.get_default_graph)    #but not the  default graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x *3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
      "          37.88      , -122.23      ],\n",
      "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
      "          37.86      , -122.22      ],\n",
      "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
      "          37.85      , -122.24      ],\n",
      "       ...,\n",
      "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
      "          39.43      , -121.22      ],\n",
      "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
      "          39.43      , -121.32      ],\n",
      "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
      "          39.37      , -121.24      ]]), 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]), 'feature_names': ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'], 'DESCR': 'California housing dataset.\\n\\nThe original database is available from StatLib\\n\\n    http://lib.stat.cmu.edu/datasets/\\n\\nThe data contains 20,640 observations on 9 variables.\\n\\nThis dataset contains the average house value as target variable\\nand the following input variables (features): average income,\\nhousing average age, average rooms, average bedrooms, population,\\naverage occupation, latitude, and longitude in that order.\\n\\nReferences\\n----------\\n\\nPace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\nStatistics and Probability Letters, 33 (1997) 291-297.\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]    #added a column vector of m 1s\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "#In the evaluation phase, we will have to evaluate theta\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "\n",
    "#This was the normal equation method\n",
    "print(housing)    #what the data looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually computing Gradients for GD\n",
    "#### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE =  8.065985\n",
      "Epoch:  100 MSE =  5.0069027\n",
      "Epoch:  200 MSE =  4.9445987\n",
      "Epoch:  300 MSE =  4.90945\n",
      "Epoch:  400 MSE =  4.883471\n",
      "Epoch:  500 MSE =  4.864137\n",
      "Epoch:  600 MSE =  4.849684\n",
      "Epoch:  700 MSE =  4.838844\n",
      "Epoch:  800 MSE =  4.8306704\n",
      "Epoch:  900 MSE =  4.824484\n",
      "Best theta:  [[-0.27591395]\n",
      " [ 0.8861117 ]\n",
      " [ 0.16327482]\n",
      " [-0.30879635]\n",
      " [ 0.31356624]\n",
      " [ 0.01096052]\n",
      " [-0.04429711]\n",
      " [-0.52227587]\n",
      " [-0.49643603]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "n_epochs = 1000    #times it will do forward and backward passes\n",
    "learning_rate = 0.01\n",
    "\n",
    "#We need to scale the Data for Gradient Descent\n",
    "scaler = StandardScaler().fit(housing_data_plus_bias)\n",
    "scaled_housing_data_plus_bias = scaler.transform(housing_data_plus_bias)\n",
    "\n",
    "#Construction phase\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")    #tensor containing random values, given shape and range\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "#gradients = 2/m * tf.matmul(tf.transpose(X), error)    #-> Normal way\n",
    "gradients = tf.gradients(mse, [theta])[0]              #-> Tensorflow way (efficient and accurate)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)    #theta = theta - lr*gradients\n",
    "\n",
    "\n",
    "#Execution Phase\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"MSE = \", mse.eval())\n",
    "        sess.run(training_op)    #we construct the best theta here, eval later to find best\n",
    "    best_theta = theta.eval()\n",
    "print(\"Best theta: \", best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add this in place of the gradients = [...] line\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "#training_op = optimizer.minimize(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:  [[-0.27219152]\n",
      " [ 0.8377844 ]\n",
      " [ 0.10645497]\n",
      " [-0.25947902]\n",
      " [ 0.29196444]\n",
      " [ 0.00181689]\n",
      " [ 0.2128084 ]\n",
      " [-0.89034677]\n",
      " [-0.85242176]]\n"
     ]
    }
   ],
   "source": [
    "#to feed data to algorithm, we make some modifications to the code:\n",
    "\n",
    "#Construction phase\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  \n",
    "    indices = np.random.randint(m, size=batch_size) \n",
    "    X_batch = scaled_housing_data_plus_bias[indices] \n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch \n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")    #tensor containing random values, given shape and range\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "#gradients = 2/m * tf.matmul(tf.transpose(X), error)    #-> Normal way\n",
    "gradients = tf.gradients(mse, [theta])[0]              #-> Tensorflow way (efficient and accurate)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)    #theta = theta - lr*gradients\n",
    "\n",
    "\n",
    "#Execution Phase\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})    #placeholders are fed with this dict\n",
    "        best_theta = theta.eval()\n",
    "            \n",
    "print(\"Best theta: \", best_theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and restoring models\n",
    "\n",
    "- Create a Saver node at the end of construction phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE =  8.813791\n",
      "Epoch:  100 MSE =  5.139094\n",
      "Epoch:  200 MSE =  4.9726214\n",
      "Epoch:  300 MSE =  4.922286\n",
      "Epoch:  400 MSE =  4.889352\n",
      "Epoch:  500 MSE =  4.8657355\n",
      "Epoch:  600 MSE =  4.8486533\n",
      "Epoch:  700 MSE =  4.836275\n",
      "Epoch:  800 MSE =  4.827299\n",
      "Epoch:  900 MSE =  4.8207903\n",
      "Best theta:  [[-0.22573972]\n",
      " [ 0.7267378 ]\n",
      " [ 0.14211889]\n",
      " [ 0.00863735]\n",
      " [ 0.04389765]\n",
      " [ 0.00533218]\n",
      " [-0.0391091 ]\n",
      " [-0.82614493]\n",
      " [-0.7809662 ]]\n"
     ]
    }
   ],
   "source": [
    "#Construction phase\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")    #tensor containing random values, given shape and range\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "#gradients = 2/m * tf.matmul(tf.transpose(X), error)    #-> Normal way\n",
    "gradients = tf.gradients(mse, [theta])[0]              #-> Tensorflow way (efficient and accurate)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)    #theta = theta - lr*gradients\n",
    "\n",
    "#Saver:\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#Execution Phase\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"MSE = \", mse.eval())\n",
    "        sess.run(training_op)    #we construct the best theta here, eval later to find best\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/ycModel.ckpt\")\n",
    "print(\"Best theta: \", best_theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To  restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of using the init node during execution,\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"tmp/ycModel.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing with TensorBoard\n",
    "\n",
    "- We need to use a different log directory everytime we run our program, else tf merges stats from two runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()    #Clears the default graph stack and resets the global default graph.\n",
    "\n",
    "from datetime import datetime  \n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}\".format(root_logdir, now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction phase\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")    #tensor containing random values, given shape and range\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "#gradients = 2/m * tf.matmul(tf.transpose(X), error)    #-> Normal way\n",
    "gradients = tf.gradients(mse, [theta])[0]              #-> Tensorflow way (efficient and accurate)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)    #theta = theta - lr*gradients\n",
    "\n",
    "#Adding at end of construction for tensorboard:\n",
    "mse_summary = tf.summary.scalar('MSE', mse)    #binary log string\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:  [[ 0.6303098 ]\n",
      " [ 0.8377844 ]\n",
      " [ 0.10645497]\n",
      " [-0.25947902]\n",
      " [ 0.29196444]\n",
      " [ 0.00181689]\n",
      " [ 0.2128084 ]\n",
      " [-0.89034677]\n",
      " [-0.85242176]]\n"
     ]
    }
   ],
   "source": [
    "#Execution Phase\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            \n",
    "            #Adding for tensorboard:\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "        \n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})    #placeholders are fed with this dict\n",
    "        best_theta = theta.eval()\n",
    "            \n",
    "print(\"Best theta: \", best_theta)\n",
    "#close FileWriter at the end of program\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
